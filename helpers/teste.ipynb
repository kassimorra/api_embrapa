{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Comercio.csv',\n",
       " 'ExpEspumantes.csv',\n",
       " 'ExpSuco.csv',\n",
       " 'ExpUva.csv',\n",
       " 'ExpVinho.csv',\n",
       " 'ImpEspumantes.csv',\n",
       " 'ImpFrescas.csv',\n",
       " 'ImpPassas.csv',\n",
       " 'ImpSuco.csv',\n",
       " 'ImpVinhos.csv',\n",
       " 'ProcessaAmericanas.csv',\n",
       " 'ProcessaMesa.csv',\n",
       " 'ProcessaSemclass.csv',\n",
       " 'ProcessaViniferas.csv',\n",
       " 'Producao.csv',\n",
       " '__init__.py']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFilesRead = []\n",
    "\n",
    "path = \"D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/\"\n",
    "for file in os.listdir(path):\n",
    "    if(file.find(\"Processa\") == -1):\n",
    "        allFilesRead.append(pd.read_csv(path+file, sep=\";\"))\n",
    "    else:\n",
    "        allFilesRead.append(pd.read_csv(path+file, sep=\"\\t\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictCol = {\n",
    "            \"id\" : int,\n",
    "            \"control\" : str,\n",
    "            \"produto\" : str,\n",
    "            \"pais\" : str,\n",
    "            \"cultivar\" : str\n",
    "            }\n",
    "\n",
    "def ajustNameColumns(col):\n",
    "    colSemAcento = unidecode(col)\n",
    "    return colSemAcento.lower()\n",
    "    \n",
    "for i, file in enumerate(allFilesRead):\n",
    "    file.rename(columns= ajustNameColumns, inplace=True)\n",
    "    for col in file.columns:\n",
    "        if(col in dictCol):\n",
    "            file[col] = file[col].astype(dictCol.get(col))\n",
    "        else:\n",
    "            file[col].infer_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'África do Sul'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m dictCol \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m      3\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontrol\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcultivar\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;28mstr\u001b[39m\n\u001b[0;32m      7\u001b[0m             }\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mallFilesRead\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPaís\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictCol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mqualquercoisa\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\PosTech Fiap - Machine Learning Enginieer\\Git-Atividades\\api_embrapa\\api_embrapa\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   6639\u001b[0m     ]\n\u001b[0;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\PosTech Fiap - Machine Learning Enginieer\\Git-Atividades\\api_embrapa\\api_embrapa\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\PosTech Fiap - Machine Learning Enginieer\\Git-Atividades\\api_embrapa\\api_embrapa\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32md:\\PosTech Fiap - Machine Learning Enginieer\\Git-Atividades\\api_embrapa\\api_embrapa\\venv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\PosTech Fiap - Machine Learning Enginieer\\Git-Atividades\\api_embrapa\\api_embrapa\\venv\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32md:\\PosTech Fiap - Machine Learning Enginieer\\Git-Atividades\\api_embrapa\\api_embrapa\\venv\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32md:\\PosTech Fiap - Machine Learning Enginieer\\Git-Atividades\\api_embrapa\\api_embrapa\\venv\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'África do Sul'"
     ]
    }
   ],
   "source": [
    "dictCol = {\n",
    "            \"id\" : int,\n",
    "            \"control\" : str,\n",
    "            \"produto\" : str,\n",
    "            \"pais\" : str,\n",
    "            \"cultivar\" : str\n",
    "            }\n",
    "print(allFilesRead[2]['País'].astype(dictCol.get('qualquercoisa')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'pais', '1970', '1970.1', '1971', '1971.1', '1972', '1972.1',\n",
      "       '1973', '1973.1',\n",
      "       ...\n",
      "       '2019', '2019.1', '2020', '2020.1', '2021', '2021.1', '2022', '2022.1',\n",
      "       '2023', '2023.1'],\n",
      "      dtype='object', length=110)\n",
      "      id                 pais  1970  1970.1  1971  1971.1  1972  1972.1  1973  \\\n",
      "0      1        África do Sul     0       0     0       0     0       0     0   \n",
      "1      2             Alemanha     0       0     0       0     0       0     0   \n",
      "2      3               Angola     0       0     0       0     0       0     0   \n",
      "3      4    Antigua e Barbuda     0       0     0       0     0       0     0   \n",
      "4      5  Antilhas Holandesas     0       0     0       0     0       0     0   \n",
      "..   ...                  ...   ...     ...   ...     ...   ...     ...   ...   \n",
      "98    99              Uruguai     0       0     0       0     0       0     0   \n",
      "99   100              Vanuatu     0       0     0       0     0       0     0   \n",
      "100  101            Venezuela     0       0     0       0     0       0     0   \n",
      "101  102               Vietnã     0       0     0       0     0       0     0   \n",
      "102  103            Outros(1)  5132    3208     0       0  1200     579   144   \n",
      "\n",
      "     1973.1  ...  2019  2019.1  2020  2020.1  2021  2021.1   2022  2022.1  \\\n",
      "0         0  ...     0       0     0       0     0       0      0       0   \n",
      "1         0  ...  1003    5466  2388   14767   142     265   1164    6560   \n",
      "2         0  ...  1007    3615    24      38     0       0  26383  141588   \n",
      "3         0  ...     7      34    32     328    10      82     65     146   \n",
      "4         0  ...     0       0     0       0     0       0      0       0   \n",
      "..      ...  ...   ...     ...   ...     ...   ...     ...    ...     ...   \n",
      "98        0  ...  2808   15045  1796   15322     0       0  10200   87895   \n",
      "99        0  ...     0       0    14      31     0       0      0       0   \n",
      "100       0  ...   450    2670     0       0     0       0      0       0   \n",
      "101       0  ...     0       0     0       0   144     374     16      19   \n",
      "102     102  ...     0       0     0       0     0       0      0       0   \n",
      "\n",
      "      2023  2023.1  \n",
      "0        2      44  \n",
      "1      162    1542  \n",
      "2    56242  315073  \n",
      "3       24     100  \n",
      "4        0       0  \n",
      "..     ...     ...  \n",
      "98    2812   14352  \n",
      "99       0       0  \n",
      "100      0       0  \n",
      "101      0       0  \n",
      "102      0       0  \n",
      "\n",
      "[103 rows x 110 columns]\n"
     ]
    }
   ],
   "source": [
    "from unidecode import unidecode\n",
    "df = allFilesRead[1]\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "def processar_nome_coluna(nome_coluna):\n",
    "    nome_sem_acentos = unidecode(nome_coluna)\n",
    "    return nome_sem_acentos.lower()\n",
    "\n",
    "df.rename(columns=processar_nome_coluna, inplace=True)\n",
    "\n",
    "print(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'País'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct2Find = r\"\\b\\d+\\.\\d+\\b\"\n",
    "\n",
    "\n",
    "for df in allFilesRead:\n",
    "    for col in df:\n",
    "        if(re.findall(struct2Find,col)):\n",
    "            newName = col.split(\".\")[0]\n",
    "            col = df.rename(columns={col: newName}, inplace=True)\n",
    "\n",
    "for df in allFilesRead:\n",
    "    duplicatedColumns = df.columns[df.columns.duplicated()]\n",
    "    for col in duplicatedColumns:\n",
    "        dfMiddle = df[col].sum(axis=1)\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "        df[col] = dfMiddle\n",
    "\n",
    "print(allFilesRead[2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_coluna_A = [1, 2, 3, 4, 5, 6, None]  # 6 elementos\n",
    "dados_coluna_B = [1, 2, 3, 4, 5, 6,7]  # 5 elementos\n",
    "\n",
    "data = {\n",
    "    '1990': dados_coluna_A,\n",
    "    '1990.1': dados_coluna_B\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "struct2Find = r\"\\b\\d+\\.\\d+\\b\"\n",
    "\n",
    "for col in df:\n",
    "    if(re.findall(struct2Find,col)):\n",
    "        newName = col.split(\".\")[0]\n",
    "        col = df.rename(columns={col: newName}, inplace=True)\n",
    "\n",
    "duplicatedColumns = df.columns[df.columns.duplicated()]\n",
    "for col in duplicatedColumns:\n",
    "    dfMiddle = df[col].sum(axis=1)\n",
    "    df.drop(col, axis=1, inplace=True)\n",
    "    df[col] = dfMiddle\n",
    "\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/Comercio.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ExpEspumantes.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ExpSuco.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ExpUva.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ExpVinho.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ImpEspumantes.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ImpFrescas.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ImpPassas.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ImpSuco.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ImpVinhos.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ProcessaAmericanas.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ProcessaMesa.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ProcessaSemclass.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ProcessaViniferas.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/Producao.csv')\n"
     ]
    }
   ],
   "source": [
    "path = \"D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/\"\n",
    "pathFiles = ()\n",
    "a = []\n",
    "for arq in os.listdir(path):\n",
    "    a.append(path+arq)\n",
    "pathFiles = tuple(a)\n",
    "print(pathFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "        \n",
    "class etlFiles:\n",
    "    def __init__(self):\n",
    "        path = \"D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/\"\n",
    "        a = []\n",
    "        for file in os.listdir(path):\n",
    "            a.append(path+file)\n",
    "                    \n",
    "        self.pathFiles = tuple(a)\n",
    "        print(pathFiles)\n",
    "        self.allFilesList = []\n",
    "        self.file = pd.DataFrame\n",
    "        self.dictCol = {\n",
    "                        \"id\" : int,\n",
    "                        \"control\" : str,\n",
    "                        \"produto\" : str,\n",
    "                        \"pais\" : str,\n",
    "                        \"cultivar\" : str\n",
    "                        }\n",
    "\n",
    "    def readAllFiles(self,index):\n",
    "        if(index != -1):\n",
    "            #embrapaFiles.embrapaDownloadAll()\n",
    "            if(len(os.listdir(self.pathFiles[0]).split(\"/\")[0]) != 0):\n",
    "                allFilesRead = []\n",
    "                for file in os.listdir(self.pathFiles[index]):\n",
    "                    if(file.find(\"Processa\") == -1):\n",
    "                        allFilesRead.append(pd.read_csv(file, sep=\";\"))\n",
    "                    else:\n",
    "                        allFilesRead.append(pd.read_csv(file, sep=\"\\t\"))\n",
    "                        \n",
    "                self.allFilesList = allFilesRead\n",
    "            else:\n",
    "                raise ValueError(\"Falha na leitura dos arquivos\")\n",
    "        else:\n",
    "            #embrapaFiles.embrapaDownloadFile(index)\n",
    "            if(os.path.isfile(self.pathFiles[index])):\n",
    "                path = self.pathFiles[index]\n",
    "                if(path.find(\"Processa\") == -1):\n",
    "                    file = pd.read_csv(path, sep=\";\")\n",
    "                else:\n",
    "                    file = pd.read_csv(path, sep=\"\\t\")\n",
    "                self.file = file\n",
    "            else:\n",
    "                raise ValueError(\"Falha na leitura do arquivo\")\n",
    "            \n",
    "    def returnAllFiles(self):\n",
    "        return self.allFilesList\n",
    "    \n",
    "    def returnFile(self):\n",
    "        return self.file\n",
    "\n",
    "    def subNoneAsZero(self, index):\n",
    "        if(index != -1):\n",
    "            if (len(self.allFilesList) != 0):\n",
    "                for i, file in enumerate(self.allFilesList):\n",
    "                    self.allFilesList[i] = self.allFilesList[i].fillna(0)\n",
    "            else:\n",
    "                raise ValueError(\"Falha ao retirar valores nulos\")\n",
    "        else:\n",
    "            self.file = self.file.fillna(0)\n",
    "        \n",
    "    \n",
    "    def clearNullValues(self,index):\n",
    "        if(index != -1):\n",
    "            if (len(self.allFilesList) != 0):\n",
    "                for i, file in enumerate(self.allFilesList):\n",
    "                    self.allFilesList[i] = self.allFilesList[i].dropna()\n",
    "            else:\n",
    "                raise ValueError(\"Falha ao retirar valores nulos\")\n",
    "        else:\n",
    "            self.file = self.file.dropna()\n",
    "    \n",
    "    def removeDuplicates(self,index):\n",
    "        if(index != -1):\n",
    "            if (len(self.allFilesList) != 0):\n",
    "                for i, file in enumerate(self.allFilesList):\n",
    "                    self.allFilesList[i] = self.allFilesList[i].dropduplicates()\n",
    "            else:\n",
    "                raise ValueError(\"Falha ao remover duplicatas\")\n",
    "        else:\n",
    "            self.file = self.file[i].dropduplicates()\n",
    "\n",
    "    def ajustTypes(self,index):\n",
    "        if(index != -1):\n",
    "            if (len(self.allFilesList) != 0):\n",
    "                for i, file in enumerate(self.allFilesList):\n",
    "                    file.rename(columns=self.ajustNameColumns, inplace=True)\n",
    "                    for col in file.columns:\n",
    "                        if(col in self.dictCol):\n",
    "                            file[col] = file[col].astype(self.dictCol.get(col))\n",
    "                        else:\n",
    "                            file[col].infer_objects()\n",
    "            else:\n",
    "                raise ValueError(\"Falha ao salvar arquivos\")\n",
    "        else:\n",
    "            self.file.rename(columns=self.ajustNameColumns, inplace=True)\n",
    "            for col in self.file.columns:\n",
    "                if(col in self.dictCol):\n",
    "                    self.file[col] = self.file[col].astype(self.dictCol.get(col))\n",
    "                else:\n",
    "                    self.file[col].infer_objects()\n",
    "                \n",
    "            \n",
    "        \n",
    "    def ajustNameColumns(col):\n",
    "        colSemAcento = unidecode(col)\n",
    "        return colSemAcento.lower()\n",
    "        \n",
    "    def ajustNameColumnsNumbs(df):\n",
    "        struct2Find = r\"\\b\\d+\\.\\d+\\b\"\n",
    "        for col in df:\n",
    "            if(re.findall(struct2Find,col)):\n",
    "                newName = col.split(\".\")[0]\n",
    "                col = df.rename(columns={col: newName}, inplace=True)\n",
    "        return df\n",
    "            \n",
    "    def sumSameColuns(self,index):\n",
    "        #Necessidade verifciar caso index não conhecida entre as colunas, como fica\n",
    "        if(index != -1):\n",
    "            if (len(self.allFilesList) != 0):\n",
    "                for i, file in enumerate(self.allFilesList):\n",
    "                    file = self.ajustNameColumnsNumbs(file)\n",
    "                    duplicatedColumns = file.columns[file.columns.duplicated()]\n",
    "                    for col in duplicatedColumns:\n",
    "                        dfMiddle = file[col].sum(axis=1)\n",
    "                        file.drop(col, axis=1, inplace=True)\n",
    "                        file[col] = dfMiddle\n",
    "            else:\n",
    "                raise ValueError(\"Falha ao remover duplicatas\")\n",
    "        else:\n",
    "            self.file = self.ajustNameColumnsNumbs(self.file)\n",
    "            duplicatedColumns = self.file.columns[self.file.columns.duplicated()]\n",
    "            for col in duplicatedColumns:\n",
    "                dfMiddle = self.file[col].sum(axis=1)\n",
    "                self.file.drop(col, axis=1, inplace=True)\n",
    "                self.file[col] = dfMiddle\n",
    "            \n",
    "\n",
    "    def saveFiles(self,index):\n",
    "        if(index != -1):\n",
    "            if (len(self.allFilesList) != 0):\n",
    "                for i, file in enumerate(self.allFilesList):\n",
    "                    filename = \"arquivosEtl/\" + self.pathFiles[i].split(\"/\")[1]\n",
    "                    file.to_csv(filename,index=False)\n",
    "            else:\n",
    "                raise ValueError(\"Falha ao salvar arquivos\")\n",
    "        else:\n",
    "            filename = \"arquivosEtl/\" + self.pathFiles[index].split(\"/\")[1]\n",
    "            self.file.to_csv(filename,index=False)\n",
    "               \n",
    "    def makeEtl(self,index):\n",
    "        index = index\n",
    "        self.readAllFiles(index)\n",
    "        self.subNoneAsZero(index)\n",
    "        #self.clearNullValues(self,index)\n",
    "        self.ajustTypes(index)\n",
    "        self.sumSameColuns(index)\n",
    "        self.removeDuplicates(index)\n",
    "        self.saveFiles(index)\n",
    "        if(index == -1):\n",
    "            self.returnAllFiles()\n",
    "        else:\n",
    "            self.returnFile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (2266096864.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[134], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    os.listdir(pathFiles[0]).split(\"/\")[0])\u001b[0m\n\u001b[1;37m                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "os.listdir(pathFiles[0]).split(\"/\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] O nome do diretório é inválido: 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/Comercio.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[136], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathFiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m: [WinError 267] O nome do diretório é inválido: 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/Comercio.csv'"
     ]
    }
   ],
   "source": [
    "os.listdir(pathFiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/Comercio.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ExpEspumantes.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ExpSuco.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ExpUva.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ExpVinho.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ImpEspumantes.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ImpFrescas.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ImpPassas.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ImpSuco.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ImpVinhos.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ProcessaAmericanas.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ProcessaMesa.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ProcessaSemclass.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/ProcessaViniferas.csv', 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/Producao.csv')\n"
     ]
    },
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] O nome do diretório é inválido: 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/Comercio.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[140], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m etl \u001b[38;5;241m=\u001b[39m etlFiles()\n\u001b[1;32m----> 2\u001b[0m \u001b[43metl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakeEtl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[1;32mIn[139], line 160\u001b[0m, in \u001b[0;36metlFiles.makeEtl\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmakeEtl\u001b[39m(\u001b[38;5;28mself\u001b[39m,index):\n\u001b[0;32m    159\u001b[0m     index \u001b[38;5;241m=\u001b[39m index\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadAllFiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubNoneAsZero(index)\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m#self.clearNullValues(self,index)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[139], line 30\u001b[0m, in \u001b[0;36metlFiles.readAllFiles\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadAllFiles\u001b[39m(\u001b[38;5;28mself\u001b[39m,index):\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(index \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;66;03m#embrapaFiles.embrapaDownloadAll()\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpathFiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     31\u001b[0m             allFilesRead \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     32\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpathFiles[index]):\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m: [WinError 267] O nome do diretório é inválido: 'D:/PosTech Fiap - Machine Learning Enginieer/Git-Atividades/api_embrapa/api_embrapa/arquivos/Comercio.csv'"
     ]
    }
   ],
   "source": [
    "etl = etlFiles()\n",
    "etl.makeEtl(0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D:\\PosTech Fiap - Machine Learning Enginieer\\Git-Atividades\\api_embrapa\\api_embrapa\\arquivos\\Producao.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
